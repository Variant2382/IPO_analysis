# -*- coding: utf-8 -*-
"""tweet_collection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sOwvgXe-F-qM9l4gz7MU3fMFcWfJcolx
"""

import tweepy
from textblob import TextBlob
from wordcloud import WordCloud
import pandas as pd
import numpy as np
import re
import matplotlib.pyplot as plt
plt.style.use('fivethirtyeight')
import time

consumerBearerToken= "AAAAAAAAAAAAAAAAAAAAAKZebQEAAAAAqqLLDk%2F3VnjgFEkN9Z%2FdDkBjZwA%3DBEfa8ApRE0OqZn57cSNtx0ECIhDhKoqC7uinaAxZpu0wcwrPKl"
client = tweepy.Client(consumerBearerToken)

query = "(paytmipo OR paytm ipo OR vijay shekhar) lang:en -has:media -is:retweet -is:nullcast -nykaa"
start = "2021-10-26T10:00:00z"
end = "2021-11-18T03:30:00z"

main_text=[]
main_time=[]
like_count=[]

posts = client.search_all_tweets(query=query, start_time = start, end_time = end, max_results = 100, tweet_fields = ['created_at','public_metrics','text'])

next_element = posts.meta
next_token = next_element["next_token"]

for tweet in posts.data:
    main_text.append(tweet.text)
    main_time.append(tweet.created_at)
    like_count.append(tweet.public_metrics["like_count"])

i = 1
while i <= 1:
    time.sleep(1)
    sec_posts = client.search_all_tweets(query=query, start_time = start, end_time = end, max_results = 100, next_token= next_token, tweet_fields = ['created_at','public_metrics','text'])
    next_element = sec_posts.meta
#    next_token = next_element["next_token"]
    i = i + 1;
    
    for tweet in sec_posts.data:
        main_text.append(tweet.text)
        main_time.append(tweet.created_at)
        like_count.append(tweet.public_metrics["like_count"])

i=0;
for tweet in main_text:
    
    print(str(i) + ') ' + tweet + '\n\n')
    i= i+1;

def cleanText (text):
    text = re.sub(r'@[A-Za-z0-9]+', '', text) 
    text = re.sub(r'#', '', text)
    text = re.sub(r'RT[\s]+','', text)
    text = re.sub(r'https?:\/\/\S+', '', text)
    text = re.sub(r'@ ',' ', text)
    text = re.sub(r'\n', ' ', text)
    text = re.sub(r'n ', ' ', text)
    text = re.sub(r'xa0+', '', text)
    text = re.sub(r'[^a-zA-Z0-9]', ' ', text)
    text = re.sub(r' +', ' ', text)

    
    return text



cleanedText=[]

for text in main_text:
    
    new_text = str(text)[0:-1]
    
    cleanedText.append(cleanText(new_text))



import pandas as pd  
  
     
# list of name, degree, score 
create = main_time
text = cleanedText 
like = like_count
     
# dictionary of lists  
dict = {'Time': create, 'Text': text, 'Likes': like}  
       
df = pd.DataFrame(dict) 
    
# saving the dataframe 
df.to_csv('Paytm.csv')

